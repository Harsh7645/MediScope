{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Knowledge Base Integration**"
      ],
      "metadata": {
        "id": "irkihHsjaA21"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Phase 3 Results & Setup**"
      ],
      "metadata": {
        "id": "GcObrUNWaG_S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isW7LNrJZmTA",
        "outputId": "005ea4d2-610b-4a80-a469-391a1057f832"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "               PHASE 4: KNOWLEDGE BASE INTEGRATION\n",
            "======================================================================\n",
            "\n",
            "üìÇ Loading NER results from Phase 3...\n",
            "‚úÖ Loaded 10 NER results\n",
            "   Drug names found: 0/10 (0.0%)\n",
            "   Unique drug names: 0\n",
            "   Sample drugs: \n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# PHASE 4: KNOWLEDGE BASE INTEGRATION\n",
        "# Load Previous Results and Setup\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\" \" * 15 + \"PHASE 4: KNOWLEDGE BASE INTEGRATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# If starting fresh session, mount drive and load data\n",
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "from functools import lru_cache\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Mount drive if not already mounted\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"‚úÖ Google Drive mounted\")\n",
        "\n",
        "# Load paths\n",
        "project_name = \"MediScope_OCR_Project\"\n",
        "drive_project_path = f\"/content/drive/MyDrive/{project_name}\"\n",
        "phase3_drive_path = os.path. join(drive_project_path, \"Phase3_NER\")\n",
        "\n",
        "# Load NER results\n",
        "print(\"\\nüìÇ Loading NER results from Phase 3...\")\n",
        "ner_results_path = os.path.join(phase3_drive_path, 'ner_extraction_results.csv')\n",
        "\n",
        "if os.path.exists(ner_results_path):\n",
        "    ner_results_df = pd.read_csv(ner_results_path)\n",
        "    print(f\"‚úÖ Loaded {len(ner_results_df)} NER results\")\n",
        "\n",
        "    # Show drug extraction stats\n",
        "    drug_found = ner_results_df['drug_name'].notna().sum()\n",
        "    print(f\"   Drug names found: {drug_found}/{len(ner_results_df)} ({drug_found/len(ner_results_df):.1%})\")\n",
        "\n",
        "    # Show unique drugs\n",
        "    unique_drugs = ner_results_df['drug_name'].dropna().unique()\n",
        "    print(f\"   Unique drug names: {len(unique_drugs)}\")\n",
        "\n",
        "    # Sample drugs\n",
        "    print(f\"   Sample drugs: {', '.join(list(unique_drugs)[:10])}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  NER results not found!  Please complete Phase 3 first.\")\n",
        "    ner_results_df = None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 16: Download Drug Databases**"
      ],
      "metadata": {
        "id": "Xz7R8F5saeuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" \" * 20 + \"Step 16: Download REAL Drug Databases\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import json\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from tqdm import tqdm # Added import\n",
        "import time # Added import\n",
        "import os # Added import for self-containment\n",
        "import pandas as pd # Added import for self-containment\n",
        "\n",
        "class ComprehensiveDrugDatabaseDownloader:\n",
        "    \"\"\"\n",
        "    Download real, comprehensive drug databases from multiple sources\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_dir='drug_databases'):\n",
        "        self.output_dir = output_dir\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        self.databases = []\n",
        "\n",
        "    # ========================================================================\n",
        "    # METHOD 1: RxNorm API (NIH - National Library of Medicine)\n",
        "    # ========================================================================\n",
        "\n",
        "    def download_rxnorm_drugs(self, max_drugs=5000):\n",
        "        \"\"\"\n",
        "        Download drug information from RxNorm API (FREE, comprehensive)\n",
        "        RxNorm contains ~100,000+ drug concepts\n",
        "        \"\"\"\n",
        "        print(\"\\nüì• Downloading from RxNorm API (NIH)...\")\n",
        "        print(f\"   This may take 10-15 minutes for {max_drugs} drugs...\")\n",
        "\n",
        "        base_url = \"https://rxnav.nlm.nih.gov/REST\"\n",
        "\n",
        "        drugs_data = []\n",
        "\n",
        "        # Get all drug names first\n",
        "        print(\"   Step 1: Getting drug names...\")\n",
        "\n",
        "        try:\n",
        "            # Get all drugs with RxNorm\n",
        "            url = f\"{base_url}/allconcepts.json?tty=IN\"  # IN = Ingredient - Fixed typo here!\n",
        "            response = requests.get(url, timeout=30)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "                all_drugs = data.get('minConceptGroup', {}).get('minConcept', [])\n",
        "\n",
        "                print(f\"   Found {len(all_drugs)} drug ingredients\")\n",
        "\n",
        "                # Limit to max_drugs\n",
        "                drugs_to_process = all_drugs[:max_drugs]\n",
        "\n",
        "                print(f\"   Step 2: Getting details for {len(drugs_to_process)} drugs...\")\n",
        "\n",
        "                for idx, drug in enumerate(tqdm(drugs_to_process, desc=\"Fetching RxNorm\")):\n",
        "                    try:\n",
        "                        rxcui = drug['rxcui']\n",
        "                        drug_name = drug['name']\n",
        "\n",
        "                        # Get drug properties\n",
        "                        prop_url = f\"{base_url}/rxcui/{rxcui}/allProperties.json?prop=all\"\n",
        "                        prop_response = requests.get(prop_url, timeout=5)\n",
        "\n",
        "                        drug_info = {\n",
        "                            'drug_name': drug_name,\n",
        "                            'rxcui': rxcui,\n",
        "                            'source': 'rxnorm',\n",
        "                            'generic_name': drug_name,\n",
        "                        }\n",
        "\n",
        "                        if prop_response.status_code == 200:\n",
        "                            props = prop_response.json()\n",
        "\n",
        "                            # Extract properties\n",
        "                            if 'propConceptGroup' in props:\n",
        "                                for group in props['propConceptGroup']:\n",
        "                                    if 'propConcept' in group:\n",
        "                                        for concept in group['propConcept']:\n",
        "                                            prop_name = concept.get('propName', '')\n",
        "                                            prop_value = concept.get('propValue', '')\n",
        "\n",
        "                                            if prop_name == 'RxNorm Name':\n",
        "                                                drug_info['generic_name'] = prop_value\n",
        "                                            elif prop_name == 'TTY':\n",
        "                                                drug_info['term_type'] = prop_value\n",
        "\n",
        "                        # Get related info (drug class, etc.)\n",
        "                        related_url = f\"{base_url}/rxcui/{rxcui}/related.json?tty=IN+PIN\"\n",
        "                        related_response = requests.get(related_url, timeout=5)\n",
        "\n",
        "                        if related_response.status_code == 200:\n",
        "                            related_data = related_response.json()\n",
        "                            # Extract related information\n",
        "\n",
        "                        drugs_data.append(drug_info)\n",
        "\n",
        "                        # Rate limiting\n",
        "                        if idx % 100 == 0 and idx > 0:\n",
        "                            print(f\"   Progress: {idx}/{len(drugs_to_process)}\")\n",
        "                            time.sleep(1)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        continue\n",
        "\n",
        "                print(f\"‚úÖ Downloaded {len(drugs_data)} drugs from RxNorm\")\n",
        "\n",
        "                # Save RxNorm data\n",
        "                df = pd.DataFrame(drugs_data)\n",
        "                rxnorm_path = os.path.join(self.output_dir, 'rxnorm_drugs.csv')\n",
        "                df.to_csv(rxnorm_path, index=False)\n",
        "                print(f\"   Saved to: {rxnorm_path}\")\n",
        "\n",
        "                self.databases.append(('rxnorm', df))\n",
        "                return df\n",
        "\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è  Failed to get all concepts from RxNorm. Status code: {response.status_code}\")\n",
        "                return None\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è  RxNorm download failed: {e}\")\n",
        "            return None\n",
        "\n",
        "\n",
        "# Instantiate the downloader to run the cell\n",
        "downloader = ComprehensiveDrugDatabaseDownloader()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxDRA-vjaQ1A",
        "outputId": "732c43e4-26af-4894-d963-55f616cb9725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "                    Step 16: Download REAL Drug Databases\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================================================\n",
        "# METHOD 1: RxNorm API (NIH - National Library of Medicine)\n",
        "# ========================================================================\n",
        "\n",
        "def download_rxnorm_drugs(self, max_drugs=5000):\n",
        "    \"\"\"\n",
        "    Download drug information from RxNorm API (FREE, comprehensive)\n",
        "    RxNorm contains ~100,000+ drug concepts\n",
        "    \"\"\"\n",
        "    print(\"\\nüì• Downloading from RxNorm API (NIH)...\")\n",
        "    print(f\"   This may take 10-15 minutes for {max_drugs} drugs...\")\n",
        "\n",
        "    base_url = \"https://rxnav.nlm.nih.gov/REST\"\n",
        "\n",
        "    drugs_data = []\n",
        "\n",
        "    # Get all drug names first\n",
        "    print(\"   Step 1: Getting drug names...\")\n",
        "\n",
        "    try:\n",
        "        # Get all drugs with RxNorm\n",
        "        url = f\"{base_url}/allconcepts. json? tty=IN\"  # IN = Ingredient\n",
        "        response = requests.get(url, timeout=30)\n",
        "\n",
        "        if response. status_code == 200:\n",
        "            data = response.json()\n",
        "            all_drugs = data.get('minConceptGroup', {}).get('minConcept', [])\n",
        "\n",
        "            print(f\"   Found {len(all_drugs)} drug ingredients\")\n",
        "\n",
        "            # Limit to max_drugs\n",
        "            drugs_to_process = all_drugs[:max_drugs]\n",
        "\n",
        "            print(f\"   Step 2: Getting details for {len(drugs_to_process)} drugs...\")\n",
        "\n",
        "            for idx, drug in enumerate(tqdm(drugs_to_process, desc=\"Fetching RxNorm\")):\n",
        "                try:\n",
        "                    rxcui = drug['rxcui']\n",
        "                    drug_name = drug['name']\n",
        "\n",
        "                    # Get drug properties\n",
        "                    prop_url = f\"{base_url}/rxcui/{rxcui}/allProperties.json?prop=all\"\n",
        "                    prop_response = requests.get(prop_url, timeout=5)\n",
        "\n",
        "                    drug_info = {\n",
        "                        'drug_name': drug_name,\n",
        "                        'rxcui': rxcui,\n",
        "                        'source': 'rxnorm',\n",
        "                        'generic_name': drug_name,\n",
        "                    }\n",
        "\n",
        "                    if prop_response.status_code == 200:\n",
        "                        props = prop_response.json()\n",
        "\n",
        "                        # Extract properties\n",
        "                        if 'propConceptGroup' in props:\n",
        "                            for group in props['propConceptGroup']:\n",
        "                                if 'propConcept' in group:\n",
        "                                    for concept in group['propConcept']:\n",
        "                                        prop_name = concept. get('propName', '')\n",
        "                                        prop_value = concept.get('propValue', '')\n",
        "\n",
        "                                        if prop_name == 'RxNorm Name':\n",
        "                                            drug_info['generic_name'] = prop_value\n",
        "                                        elif prop_name == 'TTY':\n",
        "                                            drug_info['term_type'] = prop_value\n",
        "\n",
        "                    # Get related info (drug class, etc.)\n",
        "                    related_url = f\"{base_url}/rxcui/{rxcui}/related.json?tty=IN+PIN\"\n",
        "                    related_response = requests.get(related_url, timeout=5)\n",
        "\n",
        "                    if related_response.status_code == 200:\n",
        "                        related_data = related_response.json()\n",
        "                        # Extract related information\n",
        "\n",
        "                    drugs_data.append(drug_info)\n",
        "\n",
        "                    # Rate limiting\n",
        "                    if idx % 100 == 0 and idx > 0:\n",
        "                        print(f\"   Progress: {idx}/{len(drugs_to_process)}\")\n",
        "                        time.sleep(1)\n",
        "\n",
        "                except Exception as e:\n",
        "                    continue\n",
        "\n",
        "            print(f\"‚úÖ Downloaded {len(drugs_data)} drugs from RxNorm\")\n",
        "\n",
        "            # Save RxNorm data\n",
        "            df = pd.DataFrame(drugs_data)\n",
        "            rxnorm_path = os.path.join(self.output_dir, 'rxnorm_drugs.csv')\n",
        "            df.to_csv(rxnorm_path, index=False)\n",
        "            print(f\"   Saved to: {rxnorm_path}\")\n",
        "\n",
        "            self.databases.append(('rxnorm', df))\n",
        "            return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  RxNorm download failed: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "gHwqbOWQaQxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee09aa93",
        "outputId": "7e4e4aa1-66db-4265-f488-67c69681317f"
      },
      "source": [
        "rxnorm_df = downloader.download_rxnorm_drugs()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üì• Downloading from RxNorm API (NIH)...\n",
            "   This may take 10-15 minutes for 5000 drugs...\n",
            "   Step 1: Getting drug names...\n",
            "   Found 14609 drug ingredients\n",
            "   Step 2: Getting details for 5000 drugs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching RxNorm:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 4763/5000 [22:11<01:04,  3.65it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# Step 17 (UPDATED): Build Master Knowledge Base from Real Data\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\" \" * 20 + \"Step 17: Build Master Knowledge Base\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "class DrugKnowledgeBaseBuilder:\n",
        "    \"\"\"\n",
        "    Build comprehensive drug knowledge base from downloaded databases\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, database_dir='drug_databases'):\n",
        "        self.database_dir = database_dir\n",
        "        self. master_db = None\n",
        "        self. brand_mappings = None\n",
        "\n",
        "    def load_all_databases(self):\n",
        "        \"\"\"\n",
        "        Load all downloaded databases\n",
        "        \"\"\"\n",
        "        print(\"\\nüìÇ Loading downloaded databases...\")\n",
        "\n",
        "        databases = {}\n",
        "\n",
        "        # Check for WHO database\n",
        "        who_path = os.path.join(self.database_dir, 'who_essential_medicines.csv')\n",
        "        if os.path.exists(who_path):\n",
        "            databases['who'] = pd.read_csv(who_path)\n",
        "            print(f\"   ‚úÖ WHO:  {len(databases['who'])} drugs\")\n",
        "\n",
        "        # Check for RxNorm database\n",
        "        rxnorm_path = os.path. join(self.database_dir, 'rxnorm_drugs.csv')\n",
        "        if os.path.exists(rxnorm_path):\n",
        "            databases['rxnorm'] = pd.read_csv(rxnorm_path)\n",
        "            print(f\"   ‚úÖ RxNorm: {len(databases['rxnorm'])} drugs\")\n",
        "\n",
        "        # Check for FDA NDC database\n",
        "        ndc_path = os.path. join(self.database_dir, 'fda_ndc_drugs.csv')\n",
        "        if os.path.exists(ndc_path):\n",
        "            databases['fda_ndc'] = pd.read_csv(ndc_path)\n",
        "            print(f\"   ‚úÖ FDA NDC: {len(databases['fda_ndc'])} drugs\")\n",
        "\n",
        "        if not databases:\n",
        "            print(\"   ‚ö†Ô∏è  No databases found!  Using sample data...\")\n",
        "            return self._create_fallback_database()\n",
        "\n",
        "        return databases\n",
        "\n",
        "    def _create_fallback_database(self):\n",
        "        \"\"\"\n",
        "        Create enhanced fallback database with more common drugs\n",
        "        \"\"\"\n",
        "        print(\"\\nüîß Creating enhanced fallback database...\")\n",
        "\n",
        "        common_drugs = {\n",
        "            # Analgesics & Anti-inflammatory\n",
        "            'Aspirin': {'class': 'NSAID', 'use': 'Pain relief, fever reduction, anti-inflammatory, cardiovascular protection'},\n",
        "            'Paracetamol': {'class':  'Analgesic', 'use': 'Pain relief, fever reduction'},\n",
        "            'Acetaminophen': {'class': 'Analgesic', 'use': 'Pain relief, fever reduction'},\n",
        "            'Ibuprofen': {'class': 'NSAID', 'use':  'Pain relief, anti-inflammatory, fever reduction'},\n",
        "            'Naproxen': {'class': 'NSAID', 'use': 'Pain relief, anti-inflammatory'},\n",
        "            'Diclofenac': {'class':  'NSAID', 'use': 'Pain relief, anti-inflammatory'},\n",
        "\n",
        "            # Antibiotics\n",
        "            'Amoxicillin': {'class':  'Penicillin Antibiotic', 'use': 'Bacterial infections'},\n",
        "            'Azithromycin': {'class': 'Macrolide Antibiotic', 'use': 'Bacterial infections'},\n",
        "            'Ciprofloxacin': {'class': 'Fluoroquinolone', 'use': 'Bacterial infections'},\n",
        "            'Doxycycline': {'class': 'Tetracycline', 'use': 'Bacterial infections'},\n",
        "            'Cephalexin': {'class': 'Cephalosporin', 'use': 'Bacterial infections'},\n",
        "            'Metronidazole': {'class':  'Antibiotic', 'use': 'Bacterial and protozoal infections'},\n",
        "\n",
        "            # Cardiovascular\n",
        "            'Atenolol': {'class': 'Beta Blocker', 'use': 'High blood pressure, angina'},\n",
        "            'Metoprolol': {'class': 'Beta Blocker', 'use': 'High blood pressure, heart failure'},\n",
        "            'Amlodipine': {'class':  'Calcium Channel Blocker', 'use': 'High blood pressure, angina'},\n",
        "            'Lisinopril': {'class': 'ACE Inhibitor', 'use': 'High blood pressure, heart failure'},\n",
        "            'Enalapril': {'class': 'ACE Inhibitor', 'use': 'High blood pressure, heart failure'},\n",
        "            'Losartan': {'class': 'ARB', 'use': 'High blood pressure'},\n",
        "            'Hydrochlorothiazide': {'class': 'Diuretic', 'use': 'High blood pressure, edema'},\n",
        "            'Furosemide': {'class': 'Loop Diuretic', 'use': 'Edema, heart failure'},\n",
        "            'Atorvastatin': {'class': 'Statin', 'use': 'High cholesterol'},\n",
        "            'Simvastatin': {'class': 'Statin', 'use': 'High cholesterol'},\n",
        "            'Rosuvastatin': {'class': 'Statin', 'use': 'High cholesterol'},\n",
        "            'Clopidogrel': {'class':  'Antiplatelet', 'use': 'Blood clot prevention'},\n",
        "            'Warfarin': {'class': 'Anticoagulant', 'use': 'Blood clot prevention'},\n",
        "\n",
        "            # Diabetes\n",
        "            'Metformin':  {'class': 'Biguanide', 'use': 'Type 2 diabetes'},\n",
        "            'Glipizide': {'class': 'Sulfonylurea', 'use': 'Type 2 diabetes'},\n",
        "            'Glyburide': {'class': 'Sulfonylurea', 'use': 'Type 2 diabetes'},\n",
        "            'Insulin': {'class': 'Hormone', 'use': 'Diabetes mellitus'},\n",
        "\n",
        "            # Gastrointestinal\n",
        "            'Omeprazole': {'class':  'Proton Pump Inhibitor', 'use': 'GERD, ulcers, acid reflux'},\n",
        "            'Pantoprazole': {'class': 'Proton Pump Inhibitor', 'use': 'GERD, ulcers'},\n",
        "            'Esomeprazole': {'class':  'Proton Pump Inhibitor', 'use': 'GERD, ulcers'},\n",
        "            'Ranitidine': {'class': 'H2 Blocker', 'use': 'GERD, ulcers'},\n",
        "            'Ondansetron': {'class': 'Antiemetic', 'use': 'Nausea, vomiting'},\n",
        "            'Metoclopramide': {'class':  'Antiemetic', 'use': 'Nausea, GERD'},\n",
        "\n",
        "            # Respiratory\n",
        "            'Salbutamol': {'class': 'Beta-2 Agonist', 'use': 'Asthma, COPD'},\n",
        "            'Albuterol': {'class': 'Beta-2 Agonist', 'use': 'Asthma, COPD'},\n",
        "            'Montelukast': {'class': 'Leukotriene Receptor Antagonist', 'use': 'Asthma, allergies'},\n",
        "            'Budesonide': {'class': 'Corticosteroid', 'use': 'Asthma, allergic rhinitis'},\n",
        "\n",
        "            # Antihistamines & Allergies\n",
        "            'Cetirizine': {'class': 'Antihistamine', 'use':  'Allergies, hay fever'},\n",
        "            'Loratadine': {'class': 'Antihistamine', 'use':  'Allergies, hay fever'},\n",
        "            'Fexofenadine': {'class': 'Antihistamine', 'use': 'Allergies'},\n",
        "            'Diphenhydramine': {'class':  'Antihistamine', 'use': 'Allergies, sleep aid'},\n",
        "\n",
        "            # Corticosteroids\n",
        "            'Prednisone': {'class': 'Corticosteroid', 'use': 'Inflammation, autoimmune conditions'},\n",
        "            'Prednisolone': {'class': 'Corticosteroid', 'use': 'Inflammation, allergies'},\n",
        "            'Dexamethasone': {'class':  'Corticosteroid', 'use': 'Inflammation, edema'},\n",
        "            'Hydrocortisone': {'class': 'Corticosteroid', 'use': 'Inflammation, skin conditions'},\n",
        "\n",
        "            # Thyroid\n",
        "            'Levothyroxine': {'class': 'Thyroid Hormone', 'use': 'Hypothyroidism'},\n",
        "\n",
        "            # Psychiatric\n",
        "            'Sertraline': {'class': 'SSRI Antidepressant', 'use': 'Depression, anxiety'},\n",
        "            'Fluoxetine': {'class': 'SSRI Antidepressant', 'use': 'Depression, anxiety'},\n",
        "            'Escitalopram': {'class': 'SSRI Antidepressant', 'use': 'Depression, anxiety'},\n",
        "            'Amitriptyline': {'class': 'Tricyclic Antidepressant', 'use': 'Depression, neuropathic pain'},\n",
        "            'Alprazolam': {'class': 'Benzodiazepine', 'use': 'Anxiety, panic disorder'},\n",
        "            'Diazepam': {'class': 'Benzodiazepine', 'use': 'Anxiety, seizures, muscle spasms'},\n",
        "            'Lorazepam': {'class': 'Benzodiazepine', 'use': 'Anxiety'},\n",
        "\n",
        "            # Pain (Opioids)\n",
        "            'Tramadol': {'class': 'Opioid Analgesic', 'use':  'Moderate to severe pain'},\n",
        "            'Codeine': {'class': 'Opioid Analgesic', 'use': 'Pain, cough'},\n",
        "            'Morphine': {'class': 'Opioid Analgesic', 'use': 'Severe pain'},\n",
        "\n",
        "            # Vitamins & Supplements\n",
        "            'Vitamin D':  {'class': 'Vitamin', 'use': 'Bone health, immune function'},\n",
        "            'Vitamin B12': {'class': 'Vitamin', 'use': 'Anemia, nerve function'},\n",
        "            'Folic Acid': {'class': 'Vitamin', 'use':  'Anemia prevention, pregnancy'},\n",
        "            'Calcium': {'class': 'Mineral', 'use': 'Bone health'},\n",
        "            'Iron':  {'class': 'Mineral', 'use': 'Anemia'},\n",
        "\n",
        "            # Others\n",
        "            'Gabapentin': {'class': 'Anticonvulsant', 'use': 'Neuropathic pain, seizures'},\n",
        "            'Pregabalin': {'class': 'Anticonvulsant', 'use': 'Neuropathic pain, fibromyalgia'},\n",
        "            'Allopurinol': {'class':  'Xanthine Oxidase Inhibitor', 'use': 'Gout'},\n",
        "            'Tamsulosin': {'class': 'Alpha Blocker', 'use': 'Benign prostatic hyperplasia'},\n",
        "        }\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        fallback_data = []\n",
        "        for drug, info in common_drugs.items():\n",
        "            fallback_data.append({\n",
        "                'drug_name': drug,\n",
        "                'generic_name': drug,\n",
        "                'drug_class': info['class'],\n",
        "                'therapeutic_use': info['use'],\n",
        "                'source': 'fallback'\n",
        "            })\n",
        "\n",
        "        df = pd.DataFrame(fallback_data)\n",
        "        print(f\"   ‚úÖ Created fallback database with {len(df)} common drugs\")\n",
        "\n",
        "        return {'fallback': df}\n",
        "\n",
        "    def normalize_drug_name(self, name):\n",
        "        \"\"\"Normalize drug name for matching\"\"\"\n",
        "        if pd.isna(name) or not name:\n",
        "            return None\n",
        "        return str(name).lower().strip().replace('¬Æ', '').replace('‚Ñ¢', '').replace('-', ' ')\n",
        "\n",
        "    def merge_databases(self, databases):\n",
        "        \"\"\"\n",
        "        Merge all databases into master knowledge base\n",
        "        \"\"\"\n",
        "        print(\"\\nüî® Merging databases into master knowledge base...\")\n",
        "\n",
        "        all_drugs = []\n",
        "\n",
        "        for source_name, df in databases.items():\n",
        "            print(f\"   Processing {source_name}:   {len(df)} drugs\")\n",
        "\n",
        "            # Standardize column names\n",
        "            df_copy = df.copy()\n",
        "\n",
        "            # Ensure required columns exist\n",
        "            if 'drug_name' not in df_copy.columns:\n",
        "                if 'name' in df_copy.columns:\n",
        "                    df_copy['drug_name'] = df_copy['name']\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "            # Add source\n",
        "            df_copy['data_source'] = source_name\n",
        "\n",
        "            # Add normalized name\n",
        "            df_copy['drug_name_normalized'] = df_copy['drug_name'].apply(self.normalize_drug_name)\n",
        "\n",
        "            # Ensure other columns\n",
        "            for col in ['generic_name', 'drug_class', 'therapeutic_use']:\n",
        "                if col not in df_copy.columns:\n",
        "                    df_copy[col] = None\n",
        "\n",
        "            all_drugs.append(df_copy)\n",
        "\n",
        "        # Combine all\n",
        "        master = pd.concat(all_drugs, ignore_index=True)\n",
        "\n",
        "        # Remove entries without drug name\n",
        "        master = master[master['drug_name_normalized']. notna()]\n",
        "\n",
        "        print(f\"\\n   üìä Before deduplication: {len(master)} entries\")\n",
        "\n",
        "        # Deduplicate - keep entry with most information\n",
        "        master['info_completeness'] = (\n",
        "            master['generic_name'].notna().astype(int) +\n",
        "            master['drug_class'].notna().astype(int) +\n",
        "            master['therapeutic_use'].notna().astype(int)\n",
        "        )\n",
        "\n",
        "        master = master.sort_values('info_completeness', ascending=False)\n",
        "        master = master.drop_duplicates(subset=['drug_name_normalized'], keep='first')\n",
        "\n",
        "        print(f\"   üìä After deduplication:   {len(master)} unique drugs\")\n",
        "\n",
        "        self.master_db = master\n",
        "        return master\n",
        "\n",
        "    def create_brand_name_mappings(self):\n",
        "        \"\"\"\n",
        "        Create brand-to-generic name mappings\n",
        "        \"\"\"\n",
        "        print(\"\\nüìù Creating brand name mappings...\")\n",
        "\n",
        "        # Common brand-to-generic mappings\n",
        "        brand_to_generic = {\n",
        "            # Pain relievers\n",
        "            'tylenol': 'paracetamol',\n",
        "            'panadol': 'paracetamol',\n",
        "            'crocin': 'paracetamol',\n",
        "            'advil':  'ibuprofen',\n",
        "            'motrin': 'ibuprofen',\n",
        "            'brufen': 'ibuprofen',\n",
        "            'nurofen': 'ibuprofen',\n",
        "            'aleve': 'naproxen',\n",
        "            'bayer': 'aspirin',\n",
        "            'ecotrin': 'aspirin',\n",
        "            'disprin': 'aspirin',\n",
        "            'voltaren': 'diclofenac',\n",
        "\n",
        "            # Cardiovascular\n",
        "            'lipitor': 'atorvastatin',\n",
        "            'crestor': 'rosuvastatin',\n",
        "            'zocor': 'simvastatin',\n",
        "            'norvasc': 'amlodipine',\n",
        "            'prinivil': 'lisinopril',\n",
        "            'zestril': 'lisinopril',\n",
        "            'lopressor': 'metoprolol',\n",
        "            'toprol': 'metoprolol',\n",
        "            'tenormin': 'atenolol',\n",
        "            'coumadin': 'warfarin',\n",
        "            'plavix': 'clopidogrel',\n",
        "            'lasix': 'furosemide',\n",
        "\n",
        "            # Gastrointestinal\n",
        "            'prilosec': 'omeprazole',\n",
        "            'nexium':  'esomeprazole',\n",
        "            'prevacid': 'lansoprazole',\n",
        "            'protonix': 'pantoprazole',\n",
        "            'zantac': 'ranitidine',\n",
        "            'pepcid': 'famotidine',\n",
        "            'zofran': 'ondansetron',\n",
        "\n",
        "            # Antibiotics\n",
        "            'augmentin': 'amoxicillin',\n",
        "            'amoxil': 'amoxicillin',\n",
        "            'zithromax': 'azithromycin',\n",
        "            'cipro': 'ciprofloxacin',\n",
        "            'flagyl': 'metronidazole',\n",
        "            'keflex': 'cephalexin',\n",
        "\n",
        "            # Diabetes\n",
        "            'glucophage': 'metformin',\n",
        "\n",
        "            # Respiratory\n",
        "            'ventolin': 'salbutamol',\n",
        "            'proventil': 'albuterol',\n",
        "            'singulair': 'montelukast',\n",
        "\n",
        "            # Antihistamines\n",
        "            'zyrtec': 'cetirizine',\n",
        "            'claritin': 'loratadine',\n",
        "            'allegra': 'fexofenadine',\n",
        "            'benadryl':  'diphenhydramine',\n",
        "\n",
        "            # Thyroid\n",
        "            'synthroid': 'levothyroxine',\n",
        "            'levoxyl': 'levothyroxine',\n",
        "\n",
        "            # Psychiatric\n",
        "            'zoloft': 'sertraline',\n",
        "            'prozac': 'fluoxetine',\n",
        "            'lexapro':  'escitalopram',\n",
        "            'xanax': 'alprazolam',\n",
        "            'valium': 'diazepam',\n",
        "            'ativan': 'lorazepam',\n",
        "\n",
        "            # Pain (opioids)\n",
        "            'ultram': 'tramadol',\n",
        "\n",
        "            # Others\n",
        "            'neurontin': 'gabapentin',\n",
        "            'lyrica': 'pregabalin',\n",
        "            'flomax': 'tamsulosin',\n",
        "        }\n",
        "\n",
        "        # Create mappings DataFrame\n",
        "        mappings = []\n",
        "\n",
        "        for brand, generic in brand_to_generic.items():\n",
        "            # Check if generic exists in master database\n",
        "            if self.master_db is not None:\n",
        "                generic_normalized = self.normalize_drug_name(generic)\n",
        "\n",
        "                matches = self.master_db[\n",
        "                    self.master_db['drug_name_normalized'] == generic_normalized\n",
        "                ]\n",
        "\n",
        "                if not matches.empty:\n",
        "                    mappings.append({\n",
        "                        'brand_name': brand,\n",
        "                        'brand_name_normalized': self.normalize_drug_name(brand),\n",
        "                        'maps_to_generic': generic,\n",
        "                        'maps_to_normalized': generic_normalized\n",
        "                    })\n",
        "\n",
        "        self.brand_mappings = pd.DataFrame(mappings)\n",
        "\n",
        "        print(f\"   ‚úÖ Created {len(self.brand_mappings)} brand name mappings\")\n",
        "\n",
        "        return self.brand_mappings\n",
        "\n",
        "    def save_knowledge_base(self, output_dir='. '):\n",
        "        \"\"\"\n",
        "        Save master knowledge base and mappings\n",
        "        \"\"\"\n",
        "        print(\"\\nüíæ Saving knowledge base...\")\n",
        "\n",
        "        if self.master_db is not None:\n",
        "            kb_path = os.path.join(output_dir, 'medicine_knowledge_base.csv')\n",
        "            self.master_db.to_csv(kb_path, index=False)\n",
        "            print(f\"   ‚úÖ Master KB saved:  {kb_path}\")\n",
        "            print(f\"      Total drugs: {len(self.master_db)}\")\n",
        "\n",
        "        if self.brand_mappings is not None:\n",
        "            mappings_path = os.path. join(output_dir, 'medicine_knowledge_base_brand_mappings.csv')\n",
        "            self.brand_mappings.to_csv(mappings_path, index=False)\n",
        "            print(f\"   ‚úÖ Brand mappings saved:   {mappings_path}\")\n",
        "            print(f\"      Total mappings: {len(self.brand_mappings)}\")\n",
        "\n",
        "    def get_statistics(self):\n",
        "        \"\"\"\n",
        "        Get knowledge base statistics\n",
        "        \"\"\"\n",
        "        if self.master_db is None:\n",
        "            return None\n",
        "\n",
        "        stats = {\n",
        "            'total_drugs': len(self.master_db),\n",
        "            'unique_classes': self.master_db['drug_class'].nunique(),\n",
        "            'sources': self.master_db['data_source'].value_counts().to_dict(),\n",
        "            'with_generic_name': self.master_db['generic_name'].notna().sum(),\n",
        "            'with_drug_class': self.master_db['drug_class'].notna().sum(),\n",
        "            'with_therapeutic_use': self.master_db['therapeutic_use'].notna().sum(),\n",
        "            'brand_mappings': len(self. brand_mappings) if self.brand_mappings is not None else 0\n",
        "        }\n",
        "\n",
        "        return stats\n",
        "\n",
        "# ============================================================================\n",
        "# Execute Step 17\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nüöÄ Building master knowledge base...\")\n",
        "\n",
        "# Initialize builder\n",
        "kb_builder = DrugKnowledgeBaseBuilder()\n",
        "\n",
        "# Load all databases\n",
        "databases = kb_builder.load_all_databases()\n",
        "\n",
        "# Merge into master\n",
        "master_kb = kb_builder.merge_databases(databases)\n",
        "\n",
        "# Create brand mappings\n",
        "brand_mappings = kb_builder.create_brand_name_mappings()\n",
        "\n",
        "# Save everything\n",
        "kb_builder.save_knowledge_base()\n",
        "\n",
        "# Show statistics\n",
        "stats = kb_builder. get_statistics()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"KNOWLEDGE BASE STATISTICS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for key, value in stats.items():\n",
        "    if key == 'sources':\n",
        "        print(f\"\\n   Data Sources:\")\n",
        "        for source, count in value.items():\n",
        "            print(f\"      {source}: {count} drugs\")\n",
        "    else:\n",
        "        print(f\"   {key. replace('_', ' ').title()}: {value}\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Show sample drugs\n",
        "print(\"\\nüìã Sample Drugs in Knowledge Base:\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "if master_kb is not None:\n",
        "    sample = master_kb[master_kb['drug_class']. notna()]. head(10)\n",
        "\n",
        "    for idx, row in sample.iterrows():\n",
        "        print(f\"\\n{row['drug_name']}\")\n",
        "        print(f\"   Class: {row. get('drug_class', 'N/A')}\")\n",
        "        print(f\"   Use: {str(row.get('therapeutic_use', 'N/A'))[:80]}...\")\n",
        "        print(f\"   Source: {row. get('data_source', 'N/A')}\")\n",
        "\n",
        "print(\"\\n‚úÖ Step 17 Complete:   Master knowledge base built with real data!\")"
      ],
      "metadata": {
        "id": "YyeaoYGNaQuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ORdm33plaQrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ejkw8PyFaQox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GNVkeF2LaQmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o9wVMn-paQjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bZrelWDdaQhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dlPiqwtqaQen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G3rVsCrHaQcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HywmMuxlaQaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tcu_JV-uaQXv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}